{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial X\n",
    "**Разработчик: Алексей Умнов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial examples (0.2 балла)\n",
    "\n",
    "В этом разделе мы будем создавать adversarial примеры для типичной архитектуры сетей. Для начала нужно сделать простую сверточную сеть для классификации (2-3 слоя) и обучить ее до нормального качества (>98%). Для экономии времени не нужно обучать ее слишком много эпох как мы это делали ранее.\n",
    "\n",
    "*Упражнение.* Можете попробовать дома обучить сеть до сходимости и сравнить, какой из вариантов более уязвим к таким атакам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import Sampler, BatchSampler\n",
    "from torch.nn.modules.loss import MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "batch_size = 256\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./MNIST/', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,         \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    # YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "        \n",
    "def train_epoch(model, optimizer, batchsize=32):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.train()\n",
    "    for _, (x_batch, y_batch) in zip(trange(len(train_loader)), train_loader):\n",
    "        data = Variable(x_batch)\n",
    "        target = Variable(y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)   \n",
    "        \n",
    "        pred = torch.max(output, 1)[1].data.numpy()\n",
    "        acc = np.mean(pred == y_batch)\n",
    "        acc_log.append(acc)\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log = [], []\n",
    "    model.eval()\n",
    "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):  \n",
    "        data = Variable(x_batch)\n",
    "        target = Variable(y_batch)\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        \n",
    "        pred = torch.max(output, 1)[1].data.numpy()\n",
    "        acc = np.mean(pred == y_batch)\n",
    "        acc_log.append(acc)\n",
    "        \n",
    "        loss = loss.data[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history)\n",
    "    \n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log, train_acc_log = [], []\n",
    "    val_log, val_acc_log = [], []\n",
    "\n",
    "    batchsize = 32\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, opt, batchsize=batchsize)\n",
    "\n",
    "        val_loss, val_acc = test(model)\n",
    "\n",
    "        train_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        val_acc_log.append((steps * (epoch + 1), np.mean(val_acc)))\n",
    "\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)    \n",
    "        plot_history(train_acc_log, val_acc_log, title='accuracy')   \n",
    "            \n",
    "    print(\"Final error: {:.2%}\".format(1 - val_acc_log[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = ConvNet()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "train(model, opt, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем несколько изображений, которые мы будем пытаться искажать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "inputs, labels = iter(test_loader).next()\n",
    "inputs = inputs[:4]\n",
    "labels = labels[:4]\n",
    "\n",
    "def imshow(images):\n",
    "    img = images\n",
    "    img = torchvision.utils.make_grid(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "imshow(inputs)\n",
    "print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте простой способ adversarial-атаки: сделайте шаг градиентного подъема по входам (изображениям) для увеличения ошибки классификации. Подберите шаг, чтобы значения предсказания уже начинали меняться, но визуально цифра мало менялась (т.е. вы бы по-прежнему ее распознали как ту же цифру с высокой уверенностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrupt_simple(inputs, labels, model, weight):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return corrupted_inputs\n",
    "\n",
    "corrupted_inputs = corrupt_simple(inputs, labels, model, <WEIGHT>)\n",
    "imshow(corrupted_inputs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = model(corrupted_inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в таком подходе приходится уже сильно исказить изображение, чтобы ответы начали меняться. Если вместо градиента использовать только его знак (по каждой координате), то результаты получаются лучше. Реализуйте такой метод."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrupt_sign(inputs, labels, model, weight):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return corrupted_inputs\n",
    "\n",
    "corrupted_inputs = corrupt_sign(inputs, labels, model, <WEIGHT>)\n",
    "imshow(corrupted_inputs.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = model(corrupted_inputs)\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print(predicted.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим как сильно меняется точность на всей выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_network_attack(net, corrupt_function, weight):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = corrupt_function(images, labels, net, weight)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "    print('Accuracy %d %% \\n' % (100 * sum(class_correct) / sum(class_total)))\n",
    "        \n",
    "    for i in range(10):\n",
    "        print('Accuracy of %2s : %2d %%' % (\n",
    "              i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_network_attack(model, corrupt_simple, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_network_attack(model, corrupt_sign, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial networks (0.8 балла)\n",
    "\n",
    "На этом семинаре мы поработаем с adversarial-архитектурами. Мы не будем обучать полноценную генеративную модель (GAN), так как это потребует много времени, а вместо этого вернемся к задаче повышения разрешения изображений и попробуем улучшить нашу модель с помощью advesarial-подхода (получится упрощенный SRGAN).\n",
    "\n",
    "Как мы обсуждали ранее, MSE хоть и является простой и удобной метрикой, она плохо отражает визуальные характеристики изображений. Поэтому мы добавим дискриминатор, который будет пытаться отличить изображения высокого качества от наших результатов, и в модели повышающей разрешение будем пытаться его обмануть.\n",
    "\n",
    "Если это записать строго, то у нас будут две сети: $D$ - дискриминатор и $E$ - сеть, повышающая разрешение, и оптимизировать мы для них будем следующие целевые функции соответсвенно:\n",
    "\n",
    "$$\n",
    "    \\min_D \\bigl[ \\mathrm{BCE}(D(E(x_l)), 0) + \\mathrm{BCE}(D(x_h), 1) \\bigr],\n",
    "$$\n",
    "\n",
    "$$\n",
    "    \\min_E \\bigl[ \\| E(x_l) - x_h \\|_2^2 - \\lambda \\cdot \\mathrm{BCE}(D(E(x_l)), 0) \\bigr],\n",
    "$$\n",
    "\n",
    "где $BCE(l, y)$ - бинарная кросс-энтропия между ответами $l$ и метками $y$, $x_l$ - изображения низкого качества, $x_h$ - изображения высокого качества.\n",
    "\n",
    "*Упражнение.* Почему в целевой функции для $D$ нет компоненты $\\mathrm{BCE}(D(x_h), 1)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала продублируем код с позапрошлого семинара, чтобы у нас была сеть для сравнения. Используйте архитектуру с двумя сверточными слоями для простоты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,         \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_kernels = 5\n",
    "\n",
    "class SuperResolutionNetwork(nn.Module):\n",
    "    \n",
    "    # YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srcnn = SuperResolutionNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def low_res_and_high_res(images_batch):\n",
    "    result = images_batch.clone()\n",
    "    low_res_transform = transforms.Resize((14,14))\n",
    "    high_res_transform = transforms.Resize((28,28))\n",
    "    toTensorTransform = transforms.ToTensor()\n",
    "    toImageTransform = transforms.ToPILImage()\n",
    "    for i in range(images_batch.size()[0]):\n",
    "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
    "    return result\n",
    "\n",
    "def train_epoch(model, optimizer, batchsize=32):\n",
    "    loss_log = []\n",
    "    model.train()\n",
    "    for _, (x_batch_base, _) in zip(trange(len(train_loader)), train_loader):\n",
    "        x_batch = x_batch_base.float()\n",
    "        data = Variable(low_res_and_high_res(x_batch))\n",
    "        target = Variable(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)        \n",
    "        loss = F.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.data.cpu()[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log   \n",
    "\n",
    "def test(model):\n",
    "    loss_log = []\n",
    "    model.eval()\n",
    "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):    \n",
    "        x_batch = x_batch.float()\n",
    "        data = Variable(low_res_and_high_res(x_batch))\n",
    "        target = Variable(x_batch)\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, target)        \n",
    "        loss = loss.data.cpu()[0]\n",
    "        loss_log.append(loss)\n",
    "    return loss_log\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_epoch(model, opt, batchsize=batch_size)\n",
    "        val_loss = test(model)\n",
    "        train_log.extend(train_loss)\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss)))\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "opt = torch.optim.Adam(srcnn.parameters(), lr=0.005)\n",
    "train(srcnn, opt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_dataset.test_data.float() / 255\n",
    "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
    "result_cnn = srcnn(Variable(test_images_blurred))\n",
    "\n",
    "examplesCount = 6\n",
    "plt.figure(figsize=[5, 10])\n",
    "for i in range(examplesCount):\n",
    "    plt.subplot(examplesCount, 3, i * 3 + 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(test_images[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(examplesCount, 3, i * 3 + 2)\n",
    "    mse = np.mean((test_images[i].numpy() - result_cnn[i].data.numpy())**2)\n",
    "    plt.title(\"CNN, MSE={:.2}\".format(mse))\n",
    "    plt.imshow(result_cnn[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(examplesCount, 3, i * 3 + 3)\n",
    "    mse = np.mean((test_images[i].numpy() - test_images_blurred[i].numpy())**2)\n",
    "    plt.title(\"LQ, MSE={:.2}\".format(mse))\n",
    "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь переходим к adversarial модели. Создайте простую сеть (2-3 слоя) для бинарной классификации изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DiscriminatorNetwork(nn.Module):\n",
    "    \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srgan = SuperResolutionNetwork()\n",
    "disc = DiscriminatorNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При оптимизации adversarial-архитектур возникает дополнительная сложность - сети необходимо оптимизировать поочередно. Иногда для них приходится подбирать оптимальное соотношение числа шагов, но мы ограничимся вариантом 1:1. Допишите недостающий код оптимизации ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size,         \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def low_res_and_high_res(images_batch):\n",
    "    result = images_batch.clone()\n",
    "    low_res_transform = transforms.Resize((14,14))\n",
    "    high_res_transform = transforms.Resize((28,28))\n",
    "    toTensorTransform = transforms.ToTensor()\n",
    "    toImageTransform = transforms.ToPILImage()\n",
    "    for i in range(images_batch.size()[0]):\n",
    "        result[i] = toTensorTransform(high_res_transform(low_res_transform(toImageTransform(images_batch[i]))))\n",
    "    return result\n",
    "\n",
    "\n",
    "DISC_LOSS_WEIGHT = 0.1\n",
    "\n",
    "def losses(model, disc, x_batch):\n",
    "    data = Variable(low_res_and_high_res(x_batch))\n",
    "    target = Variable(x_batch)\n",
    "    output = model(data)\n",
    "\n",
    "    # YOUR CODE\n",
    "    \n",
    "    return disc_loss, model_loss\n",
    "    \n",
    "\n",
    "def train_epoch(model, disc, m_opt, d_opt, batchsize=32):\n",
    "    d_loss_log = []\n",
    "    m_loss_log = []\n",
    "    model.train()\n",
    "    for batch_num, (x_batch_base, _) in zip(trange(len(train_loader)), train_loader):\n",
    "        x_batch = x_batch_base.float()\n",
    "        d_loss, m_loss = losses(model, disc, x_batch)\n",
    "            \n",
    "        # YOUR CODE \n",
    "            \n",
    "        d_loss_log.append(d_loss.data[0])\n",
    "        m_loss_log.append(m_loss.data[0])\n",
    "    return d_loss_log, m_loss_log \n",
    "\n",
    "def test(model, disc):\n",
    "    d_loss_log = []\n",
    "    m_loss_log = []\n",
    "    model.eval()\n",
    "    for batch_num, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        d_loss, m_loss = losses(model, disc, x_batch)\n",
    "        d_loss_log.append(d_loss.data[0])\n",
    "        m_loss_log.append(m_loss.data[0])\n",
    "    return d_loss_log, m_loss_log \n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_history[0], label='train', zorder=1)\n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 1], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.title('Discriminator loss')\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_history[1], label='train', zorder=1)\n",
    "    points = np.array(val_history)\n",
    "    plt.scatter(points[:, 0], points[:, 2], marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.title('Model loss')\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def train(model, disc, m_opt, d_opt, n_epochs):\n",
    "    train_log = [[], []]\n",
    "    val_log = []\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = train_epoch(model, disc, m_opt, d_opt, batchsize=batch_size)\n",
    "        val_loss = test(model, disc)\n",
    "        train_log[0].extend(train_loss[0])\n",
    "        train_log[1].extend(train_loss[1])\n",
    "        steps = train_dataset.train_labels.shape[0] / batch_size\n",
    "        val_log.append((steps * (epoch + 1), np.mean(val_loss[0]), np.mean(val_loss[1])))\n",
    "        clear_output()\n",
    "        plot_history(train_log, val_log)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь запустим оптимизацию. Большая проблема при работе с adversarial-моделями - в том, что по графикам оптимизации мало чего понятно. То есть по ним можно увидеть какое-то совсем плохое поведение и, возможно, найти ошибки в коде, но вот понять, дообучилась ли сеть, или ее еще стоит пообучать, часто нельзя. Обычно все метрики просто колеблются вокруг константы, но при этом сеть обучается (по очереди происходит небольшое улучшение дискриминатора, а потом оно тут же убирается основной сетью).\n",
    "\n",
    "Обучите сеть на 2-3 эпохах и добейтесь, чтобы влияние adversarial-потерь было заметно (на примерах ниже). Для этого потребуется, чтобы качество дискриминатора не ушло совсем в 0. Возможно, придется немного поиграться с параметрами.\n",
    "\n",
    "Потом дома можно оставить обучение на 5-10 эпох и увидеть изменения в качестве.\n",
    "\n",
    "Также обратите внимание, что MSE для adversarial-архитектуры выходит хуже, чем обычной. Но мы так и планировали сделать - ведь MSE плохо оценивает визуальное качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m_opt = torch.optim.Adam(srgan.parameters(), lr=0.005)\n",
    "d_opt = torch.optim.Adam(disc.parameters(), lr=0.005)\n",
    "train(srgan, disc, m_opt, d_opt, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_dataset.test_data.float() / 255\n",
    "test_images_blurred = low_res_and_high_res(test_images[:100].view(-1,1,28,28))\n",
    "result_cnn = srcnn(Variable(test_images_blurred))\n",
    "result_gan = srgan(Variable(test_images_blurred))\n",
    "\n",
    "examplesCount = 6\n",
    "rows, cols = examplesCount, 4\n",
    "plt.figure(figsize=[7, 10])\n",
    "for i in range(examplesCount):\n",
    "    plt.subplot(rows, cols, i * cols + 1)\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(test_images[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(rows, cols, i * cols + 2)\n",
    "    mse = np.mean((test_images[i].numpy() - result_gan[i].data.numpy())**2)\n",
    "    plt.title(\"GAN+MSE, MSE={:.2}\".format(mse))\n",
    "    plt.title(mse)\n",
    "    plt.imshow(result_gan[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(rows, cols, i * cols + 3)\n",
    "    mse = np.mean((test_images[i].numpy() - result_cnn[i].data.numpy())**2)\n",
    "    plt.title(\"MSE, MSE={:.2}\".format(mse))\n",
    "    plt.title(mse)\n",
    "    plt.imshow(result_cnn[i].data.numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(rows, cols, i * cols + 4)\n",
    "    mse = np.mean((test_images[i].numpy() - test_images_blurred[i].numpy())**2)\n",
    "    plt.title(\"LQ, MSE={:.2}\".format(mse))\n",
    "    plt.title(mse)\n",
    "    plt.imshow(test_images_blurred[i].numpy().reshape([28, 28]), cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
